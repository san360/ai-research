Final Report:
# Quantum Computing and Cryptography: Current State and Applications

## Introduction  
Quantum computing is poised to revolutionize computing by leveraging quantum mechanical phenomena to solve certain problems exponentially faster than classical computers. This promise, however, comes with a dire implication for digital security: many widely used cryptographic systems could be broken by a sufficiently powerful quantum computer. In particular, quantum algorithms (most notably **Shor’s algorithm**) can efficiently solve the mathematical problems underpinning classical encryption schemes like RSA and elliptic-curve cryptography (ECC), exposing their vulnerabilities<sup>1</sup>. This quantum threat has spurred an urgent search for *quantum-resistant cryptography* (often called post-quantum cryptography, **PQC**): new encryption algorithms designed to withstand attacks from both classical *and* quantum computers<sup>1</sup>.

At the same time, quantum technologies also offer novel cryptographic tools – for example, *quantum key distribution (QKD)* uses quantum physics to enable provably secure communication. Researchers are thus exploring both defensive strategies (developing PQC algorithms) and alternative quantum-based cryptographic methods to secure data in the looming quantum era. Below, we review the impact of quantum computing on traditional encryption methods (RSA, ECC, symmetric ciphers), discuss the development of quantum-resistant cryptography, and highlight recent advancements and challenges in this field, drawing on insights from academia and industry.

## Impact of Quantum Computing on Traditional Encryption

### Public-Key Encryption (RSA & ECC) under Quantum Threat  
Modern public-key cryptosystems like **RSA** and **ECC** derive their security from the computational infeasibility of certain mathematical problems (integer factorization for RSA, and discrete logarithms for ECC). A quantum computer running Shor’s algorithm can **factor large integers and solve discrete log problems in polynomial time**, which means it could **break the cryptographic security of RSA and ECC** given a sufficient number of error-corrected qubits<sup>2</sup>. In effect, the core one-way functions that RSA and ECC rely on would no longer be one-way for a large-scale quantum adversary. This is not just a theoretical concern – it’s a fundamental threat: *“Shor’s algorithm… efficiently factorizes large numbers and solves discrete logarithm problems, effectively breaking the cryptographic security provided by RSA and ECC.”*<sup>2</sup>

**When might this become a practical reality?** It’s difficult to predict exactly, but experts caution that a “cryptographically relevant” quantum computer (one capable of breaking RSA/ECC keys) could emerge within the next decade or two<sup>2</sup>. In fact, the U.S. National Institute of Standards and Technology (NIST) notes that *some* experts foresee such a device **appearing in about a decade**<sup>3</sup>. Governments and industries are treating these predictions seriously: for example, more than half of experts surveyed in 2022 believed there’s a >50% chance that RSA-2048 will be broken by 2037, and the U.S. National Security Agency (NSA) aims to transition its systems to quantum-safe cryptography by 2033. While no existing quantum computer can yet crack meaningful RSA/ECC keys (today’s prototypes are far too limited in qubit count and stability), the **risk is not abstract**. There is also the concern of “**harvest now, decrypt later**” attacks: an adversary can intercept and save encrypted data today, with the intention of decrypting it in the future once quantum computing advances enough<sup>4</sup>. In other words, even data that remains safely encrypted in the near-term could be retroactively compromised when quantum capabilities arrive, which is why preparations **must begin well before** such computers come online<sup>4</sup>.

It’s worth noting recent research milestones in quantum cryptanalysis. Until a few years ago, estimates for the resources needed to break RSA were astronomical – on the order of millions of qubits and many hours of runtime. However, ongoing studies are refining these estimates. For instance, in 2019 researchers estimated that factoring a 2048-bit RSA key would require on the order of 20 million noisy qubits (with error correction) and about 8 hours of processing. A *2025 study by Craig Gidney* dramatically lowered the qubit estimate: by optimizing the quantum circuits, **RSA-2048 could potentially be factored in under a week using fewer than 1 million noisy qubits**<sup>6</sup>. This is still an enormous technological hurdle (the world’s largest quantum processors today have just a few hundred **physical** qubits), but the trend in research is toward more resource-efficient algorithms. As a point of comparison, IBM’s state-of-the-art superconducting quantum processor *“Condor”* reached 1,121 qubits in 2023 – still orders of magnitude below the requirements for breaking RSA-2048<sup>5</sup>. Moreover, those 1,121 qubits are **physical qubits**, not error-corrected logical qubits; due to error rates, achieving, say, 1,000 stable logical qubits might require tens or hundreds of thousands of physical qubits. Some experts argue that *trapped-ion* quantum computers, which have lower error rates, might need on the order of a few hundred thousand physical qubits to crack RSA, whereas superconducting qubits might require many millions (to yield a few thousand high-fidelity logical qubits),. These estimates are evolving, but the consensus is that **we are not there yet** – no quantum computer in 2025 can break RSA or ECC. **However, the lead time for transitioning to new cryptographic systems is so large (often a decade or more) that waiting until a quantum threat is imminent would be too late<sup>4</sup>.**

In summary, RSA and ECC are **destined to be rendered insecure** once sufficiently powerful quantum computers exist. The timeline is uncertain, but possibly sooner than previously expected. This has rightly been called a Y2K-like event for security — except that *not* everyone is guaranteed to upgrade in time. It underscores why active research and planning for post-quantum cryptography is critical now.

### Symmetric Encryption and Hash Functions under Quantum Attacks  
Thankfully, **symmetric-key cryptography** (e.g. block ciphers like AES, and cryptographic hash functions like SHA-256) is far more robust against quantum attacks than public-key crypto. There is no known quantum algorithm that can **exponentially** speed up attacks on symmetric algorithms. However, quantum computers do provide a *quadratic* speed-up for brute-force search via **Grover’s algorithm**. Grover’s algorithm can find a secret key or hash preimage in roughly √N steps instead of N steps, meaning it effectively cuts the complexity exponent in half,. In practical terms, this implies a **brute-force key search that would take 2^128 operations classically could be achieved with on the order of 2^64 operations on a quantum computer**. The impact is that a symmetric key’s *effective* security level is roughly halved in bits. For example, a 128-bit AES key, which is considered secure against classical attacks (≈3.4×10^38 guesses), would only offer ~64-bit security against a quantum adversary using Grover’s algorithm. In light of this, *“a quantum computer of sufficient strength can cut an AES key size in half, so the recommendation is to double your AES key length.”*<sup>5</sup> Using AES-256 (which has 256-bit keys) in place of AES-128 is a straightforward way to counteract Grover’s quadratic advantage and retain an adequate security margin for the post-quantum era<sup>5</sup>.

It’s important to stress that **Grover’s algorithm, while powerful, does not utterly undermine symmetric cryptography** the way Shor’s algorithm threatens public-key cryptography. It offers a quadratic speedup, which is significant but not game-ending. In fact, symmetric algorithms are often said to be “already safe” or at least *quantum-resistant* in the sense that a modest increase in key sizes is a sufficient defense. As one source notes, Grover’s result *“has placed symmetric encryption and hashing into the category of ‘quantum-vulnerable’ cryptography (albeit less vulnerable than public-key algorithms are to Shor’s algorithm).”* In practice, this means that all current symmetric ciphers and hash functions are expected to remain secure **if** one uses sufficiently large parameters. For instance, AES-256 and SHA-384/512 are believed to provide acceptable security against quantum attacks (AES-256’s 256-bit key would still require ~2^128 quantum operations to brute force, which is considered infeasible)<sup>5</sup>. In contrast, AES-128 or SHA-256 (with 128-bit security class) might be borderline. Even there, Grover’s algorithm has some practical limitations: it needs a quantum computer with enough qubits to process the entire search space superposition, and the speedup requires sequential quantum operations on the order of 2^(n/2) which, for large n, may be prohibitively slow due to decoherence limits. Some analyses argue that *actually executing Grover’s algorithm to search a 2^128 space is impractical without millions of qubits*, so symmetric ciphers might not even need full doubling in all scenarios,. Nonetheless, as a **prudent measure**, the industry is moving toward stronger symmetric configurations (e.g. using AES-256, and larger hash outputs or MAC keys) to hedge against any quantum advantage. 

In summary, **symmetric encryption and hash functions are not broken by quantum algorithms**, but their security *strength is reduced*. The rule of thumb is simple: **use double the key length** (or output length) to maintain the desired security level against quantum attacks<sup>5</sup>. This mitigation is already in place in many systems (for example, TLS 1.3 uses 256-bit keys for its symmetric ciphers by default, and popular protocols increasingly employ SHA-384 or SHA-512 for critical operations). Because scaling up symmetric keys is relatively cheap and easy, symmetric cryptography is considered *post-quantum ready* in a way that RSA/ECC are not,. 

## Developing Quantum-Resistant Cryptography (Post-Quantum Approaches)  

Given the threats above, the cryptographic community has been actively developing **quantum-resistant cryptography** – new algorithms that can replace RSA, ECC, and other vulnerable schemes. This field is typically referred to as **Post-Quantum Cryptography (PQC)**. These replacement algorithms are designed to run on classical computers (no quantum hardware needed) but rely on mathematical problems that **neither conventional nor quantum computers can solve efficiently**<sup>4</sup>. In other words, PQC aims for cryptographic primitives that resist known quantum attacks (including Shor’s and Grover’s algorithms). 

### Leading Post-Quantum Cryptographic Algorithms  
Researchers have explored a variety of approaches for PQC, and by now several broad families of algorithms have emerged as frontrunners. According to an academic survey, *“the different types of post-quantum cryptography”* under study include **lattice-based cryptography**, **hash-based cryptography**, **code-based cryptography**, and **multivariate polynomial cryptography**<sup>1</sup>. Each of these relies on a different hard mathematical problem that (as far as we know) is intractable even for quantum computers (unlike factoring or discrete log). The major categories can be outlined as follows:

- **Lattice-Based Cryptography:** Arguably the most promising and extensively studied family of PQC. Lattice-based schemes rely on problems like the **Shortest Vector Problem (SVP)** and the **Learning With Errors (LWE)** problem in high-dimensional lattices. These problems involve finding extremely hard-to-compute structures in a large grid of points. They have withstood decades of classical cryptanalysis and, crucially, **there are no known quantum algorithms that solve these problems efficiently**<sup>2</sup>. This makes lattice schemes strong candidates for the quantum era. Many of the leading PQC algorithms are lattice-based – for example, **CRYSTALS-Kyber** (a key encapsulation mechanism) and **CRYSTALS-Dilithium** (a digital signature scheme) are both based on structured lattice problems. Lattice schemes are attractive because they can be quite efficient and are versatile (supporting encryption, key exchange, signatures, etc.). The security of lattice cryptography rests on worst-case hardness assumptions that are believed to be very robust. As a source notes: *“Lattice-based cryptography ... is one of the most promising approaches when it comes to quantum-resistant cryptography. It’s based on the hardness of problems related to lattices (e.g., SVP and LWE). These problems are currently resistant to both classical and quantum algorithms, making lattice-based cryptography a robust candidate for securing data in a quantum era.”*<sup>2</sup>.

- **Hash-Based Cryptography:** These are schemes that derive security solely from the properties of cryptographic hash functions. Perhaps the best-known examples are **hash-based digital signatures**, like the Merkle tree signature schemes (e.g., LMS and SPHINCS+). The security of hash-based methods does not rely on algebraic problems at all, only on the preimage/resistance and collision-resistance of a hash function. Hash functions like SHA-2 or SHA-3 are not significantly threatened by quantum computers *beyond* the Grover’s algorithm speedup, which, as discussed, is a manageable quadratic effect. Indeed, a hash output can be made larger to compensate for Grover (and even Grover’s algorithm is not very efficient in practice for long outputs). Thus, hash-based signatures are a very conservative approach to PQC. They are *stateful* in simplest forms (each signature uses up part of a one-time key), though stateless variants like SPHINCS+ have been developed (at the cost of larger signatures). An article highlights that *“the primary strength of hash-based cryptography in a quantum context lies in the fact that hash functions remain resistant to quantum attacks, including those posed by Grover’s algorithm, which only offers a quadratic speedup”*<sup>2</sup>. In other words, **hash-based schemes remain secure since Grover's algorithm by itself is not enough to break them** when parameters are chosen appropriately.

- **Code-Based Cryptography:** These schemes are based on problems from error-correcting codes, such as the difficulty of decoding a general linear code. The classic example is the **McEliece cryptosystem**, proposed in the 1970s, which uses the hardness of decoding random binary Goppa codes. McEliece has stood the test of time without being broken, even as computing power grew – and it’s believed to be resistant to quantum attacks as well (no known quantum algorithm can solve general decoding significantly faster than classical algorithms). Code-based encryption typically has very **large public keys** (on the order of hundreds of kilobytes) but is extremely fast in encryption and decryption. Recent code-based proposals use other families of codes and attempt to reduce key sizes. Code-based cryptography *“has been studied for decades, exemplified by the McEliece cryptosystem… [it] offers potential resilience against quantum attacks”*<sup>2</sup>.

- **Multivariate Polynomial Cryptography:** These schemes involve cryptographic trapdoor functions based on the problem of solving systems of multivariate quadratic equations over a finite field (which is NP-hard in general). Examples include the Rainbow signature scheme (now broken) and other multivariate signature schemes. Some multivariate schemes have compact signatures and keys, but many have been cryptanalyzed over the years, and confidence in them is somewhat lower than lattice or code-based schemes. Still, a properly designed multivariate scheme with no known structural weaknesses is considered a potential quantum-resistant approach. As one source notes, *“multivariate polynomial cryptography uses systems of multivariate polynomials ... Both these methods (code-based and multivariate) offer potential resilience against quantum attacks, contributing to a diverse toolkit of quantum-resistant solutions.”*<sup>2</sup>.

Additionally, there are other niche categories (like **supersingular isogeny** based cryptography, which was another promising approach until a recent break; it involved problems on elliptic curve isogenies and led to the SIKE protocol that was later *completely broken by classical means in 2022*). Another area is **quantum cryptography** (not to be confused with PQC) – which uses quantum physics for security, discussed separately below. It’s important to have diverse approaches because we cannot be certain which hard problems will remain unbroken in the long term. Thus, having multiple independent PQC algorithms (based on unrelated assumptions) is akin to hedge bets.

**Standardization efforts:** Recognizing the importance of a timely transition, NIST launched an open international competition in 2016 to evaluate and standardize post-quantum cryptographic algorithms. After three rounds of evaluation, NIST **selected four primary algorithms in 2022** for standardization: **CRYSTALS-Kyber** (a lattice-based **KEM** for encryption/key exchange), **CRYSTALS-Dilithium** (a lattice-based **digital signature** scheme), **FALCON** (a lattice-based digital signature, using NTRU lattices), and **SPHINCS+** (a stateless hash-based **signature** scheme)<sup>2</sup>. These were chosen for their strong security and performance trade-offs among dozens of candidates analyzed. Over 2023–2024, NIST proceeded to draft and finalize standards for these algorithms. In August 2024, **NIST released the first set of **finalized post-quantum cryptography standards** (FIPS 203, 204, 205) – essentially the “recipes” for implementing Kyber (now standardized as **ML-KEM**), Dilithium (**ML-DSA**), and SPHINCS+ (**SLH-DSA**)** – and is urging organizations to begin migrating to these new algorithms as soon as possible<sup>3</sup>. (The fourth algorithm, FALCON, is slated to be standardized slightly later due to its complexity.) NIST’s process is ongoing: they are also evaluating alternate candidates (including code-based schemes like HQC and BIKE, and a second round of digital signature algorithms) to serve as backup options in case any primary scheme is later found vulnerable<sup>3</sup>. The takeaway is that **the world now has concrete quantum-resistant algorithms ready for deployment**, backed by extensive scrutiny. 

It’s also noteworthy that many real-world entities have begun experimenting with and deploying post-quantum algorithms even ahead of final standards. For example, Google and Cloudflare conducted test integrations of PQC algorithms in TLS (the protocol that secures web traffic) as early as 2019–2022, to gauge performance and compatibility. By 2023–2024, some production systems have started *hybridizing* cryptography (using a combination of classical and post-quantum keys). A recent report in March 2024 highlighted that **Cloudflare – a major internet infrastructure provider – sees nearly 2% of all TLS 1.3 connections to its servers being negotiated with post-quantum cryptography** (in a hybrid ECDHE+Kyber mode), a figure expected to reach double digits by the end of 2024. Major tech companies are also moving in step: *“Apple announced in February 2024 that it will secure iMessage with post-quantum cryptography before the end of the year, and Signal chats are already secured [with a post-quantum algorithm].”* These are significant early adopters, showing that PQC is not just academic curiosity but entering real products and services to secure data against future threats.

### Quantum Cryptography (Quantum Key Distribution and Others)  
In parallel to developing quantum-resistant algorithms that run on classical computers, another approach to secure communications in the quantum era is to *use quantum technology itself for cryptography*. The chief example of this is **Quantum Key Distribution (QKD)**. QKD involves two parties sharing encryption keys by sending photons (or other quantum particles) over a channel, in such a way that any eavesdropping on the channel will disturb the quantum states and be detected. **Quantum key distribution can provide information-theoretic security** – its security is based on the laws of physics, not computational assumptions. Even a quantum computer cannot “break” QKD encryption, because there is no math problem to attack; the secrecy comes from quantum entanglement or the no-cloning theorem rather than a large-number factoring problem.

QKD has advanced from theory to practice in the last two decades. There have been successful demonstrations over fiber optic cables, and even between a satellite and a ground station (China’s **Micius** satellite in 2017 performed QKD over >1200 km). Several companies now offer QKD devices for specialized use (mostly for government or banking data center links). QKD is a fascinating technology, but it’s not a drop-in replacement for widespread encryption needs. It typically requires a dedicated direct fiber link or line-of-sight optical link for the quantum channel, and cannot be easily used over the existing Internet routing infrastructure. Moreover, QKD only solves the key *distribution* problem – you still need classical encryption (like one-time-pad or AES) to actually encrypt the data using the shared keys. And QKD is vulnerable to “side-channel” issues – the security assumptions can be broken if the equipment is imperfect or if a malicious actor tampers with the photon sources/detectors. For these reasons, **quantum cryptography is largely seen as a complement for high-security needs rather than a general replacement**. A 2023 survey on post-quantum cryptography concluded that *“due to quantum cryptography’s present limitations it is not the viable solution it is often presented to be; it is currently better to use quantum-resistant cryptography”* . In essence, while QKD can provide ultimate security in theory, in practice it faces distance limits, infrastructure challenges, and high cost, whereas PQC algorithms can be deployed widely on existing networks and devices with a software update. 

Other “quantum” applications in cryptography include **quantum random number generators (QRNGs)**, which use quantum physical processes (like optical shot noise or radioactive decay) to produce true random numbers for cryptographic keys. High-quality randomness is essential for security, and quantum randomness is provably unpredictable. QRNG devices are commercially available and can enhance security by providing stronger keys (ensuring no hidden patterns or biases that could be exploited),. However, like QKD, QRNG is a *supplementary* technology – one still needs secure algorithms to use those random keys in. It doesn’t replace cryptographic algorithms; it just improves key generation.

In summary, **developing quantum-resistant cryptography** is a multi-faceted effort. The primary focus for broad deployment is on **PQC algorithms** (lattice, hash, code, etc.), which are nearing standardization and implementation. Alongside, **quantum cryptographic techniques** such as QKD are being explored for niche applications requiring the highest levels of security, and quantum-based randomness is enhancing key generation. The community consensus, however, is that *for most applications, robust classical algorithms (PQC) are the way forward*, given their ease of integration and broad protection spectrum .

## Recent Advancements and Ongoing Challenges  

The field of quantum computing and cryptography is rapidly evolving. There have been significant **advancements** in recent years, but also persistent **challenges** that researchers and practitioners are grappling with. Below, we outline some of the key developments and hurdles:

- **Advances in Quantum Hardware:** Quantum computing technology has progressed steadily, though it’s still in an early stage. Companies like IBM, Google, and IonQ have built devices with tens or indeed hundreds of qubits, and each year new milestones are reported (e.g., IBM’s 127-qubit and 433-qubit processors achieved in 2021–2022, and a 1,121-qubit chip announced in 2023)<sup>5</sup>. These are exciting engineering feats, but **today’s quantum computers are far from the scale needed to break encryption**. Most of these qubits are “noisy” (error-prone) and not error-corrected. A cryptographically relevant attack (like factoring a 2048-bit RSA key) is estimated to need thousands of high-quality logical qubits, which likely means millions of physical qubits with error correction. Achieving that scale could be a decade or more away, if it’s achievable at all with current approaches<sup>4</sup>. Nonetheless, progress in quantum hardware is a double-edged sword: every qubit added, and every improvement in coherence and gate fidelity, brings us a step closer to the point where breaking cryptography might be conceivable. This drives urgency in deploying quantum-safe alternatives well **before** we reach that point. A positive advancement on the defensive side is that researchers are continuously refining the resource estimates for quantum attacks (as noted earlier with the 2025 Gidney result), which helps governments and industry gauge how much time might be left and which quantum technologies (superconducting vs ion traps, etc.) might pose the earliest threats,<sup>6</sup>.

- **PQC Standardization and Implementation:** One of the brightest developments has been the successful conclusion of NIST’s PQC competition and the ongoing standardization of multiple PQC algorithms (Kyber, Dilithium, etc.)<sup>2</sup>. This international effort involved academia and industry experts vetting candidates through several rounds of cryptanalysis. The fact that **final standards were published in 2024**<sup>3</sup> means that we now have vetted tools to deploy. In terms of implementation, multiple libraries and prototype products are already available. Open-source projects like Open Quantum Safe (OQS) have integrated PQC algorithms into TLS libraries and VPN software<sup>2</sup>. Companies have begun adding support: for example, cloud providers (AWS, Cloudflare, Google Cloud) offer options for PQC in some services,. An industry use-case worth noting is how Cloudflare, as mentioned, implemented hybrid post-quantum key agreements on its network and reported real-world traffic protected by it. Another is that the messaging app Signal has reportedly integrated post-quantum encryption for its message transport. These early adopters help shake out practical issues and pave the way for broader adoption. On the government side, the U.S. Cybersecurity and Infrastructure Security Agency (CISA) and NSA have issued guidelines for starting migration to PQC, and several government pilots are underway using PQC VPNs and secure email. All these are promising signs that the ecosystem is starting to move.

- **Technical Challenges in Transition:** Migrating the world’s cryptography to quantum-safe algorithms is a **massive undertaking**, not without challenges. One issue is **performance and efficiency**. Many PQC algorithms have larger key sizes or slower operations compared to the algorithms they would replace. For instance, lattice-based schemes like Kyber and Dilithium involve matrix polynomial operations that are computationally heavier than an RSA exponentiation or ECC scalar multiply (especially on constrained devices). As a result, **quantum-resistant algorithms often require significantly more computational resources**, sometimes leading to **slower performance and higher energy consumption** for cryptographic operations<sup>2</sup>. This can be problematic in low-power environments: a **smartphone, IoT sensor, or embedded controller** might struggle with the memory or CPU demands of certain PQC algorithms<sup>2</sup>. Efforts are ongoing to optimize implementations (using hardware acceleration, vector instructions, etc.), but the fact remains that post-quantum security won’t be free from a performance perspective. Another challenge is **integration and compatibility**. Swapping out cryptographic algorithms in existing protocols and systems is easier said than done. It requires updating standards (like TLS, IPsec, X.509 certificates, etc.), updating software in possibly billions of devices, and ensuring everything remains interoperable. *“Integrating new cryptographic algorithms into existing systems is a formidable task that involves updating hardware, software, and protocols without disrupting ongoing operations”*<sup>2</sup>. Compatibility issues can arise, meaning extensive testing and phased rollouts are needed. Many systems have crypto baked in at a low level (consider car computers, medical implants, ATM networks); upgrading those in the field can be very slow. Additionally, until PQC is fully tested and trusted, many organizations will adopt a **hybrid approach** (using classical and PQC algorithms in parallel for a period of time). This increases complexity in the interim. There’s also the matter of **standards and governance**: industry groups (IETF, IEEE, etc.) are still finalizing how to incorporate PQC into protocols, and regulatory bodies will likely mandate quantum-safe crypto in certain sectors, which takes time to filter down<sup>2</sup>.

- **Security and Trust Considerations:** On the cryptographic research side, a continuing challenge is to ensure the **security of proposed PQC algorithms**. Just because an algorithm survived a few years of public analysis during the NIST process doesn’t guarantee it’s unbreakable. The case of **SIKE** is instructive – it was an isogeny-based key exchange that looked promising, until in 2022 researchers found a classical attack that completely broke it in practicable time. This was a reminder that even *non-quantum* attacks can fell a candidate. Thus, cryptographers remain cautiously optimistic about the chosen algorithms, but they will continue to scrutinize them for weaknesses (both mathematical and implementation-related). We must be prepared for the possibility that a deployed PQC scheme might get broken in the future, and we’ll need alternatives or patches. NIST’s approach of standardizing a few backups and encouraging continued research is aimed at this. Another facet is **trust in new algorithms**: Organizations that have used RSA/ECC for decades may be hesitant to switch to, say, lattice-based encryption until it’s proven. There is also the matter of **patents and intellectual property** – some PQC algorithms (or their optimized implementations) are patented, which can complicate adoption if licensing isn’t handled (however, the chosen NIST algorithms were required to be freely implementable). Overall, building confidence in PQC is as much a social challenge as a technical one. It helps that the algorithms were developed in an open process and many have academic pedigrees dating back to early 2000s or before (lattice and code cryptography isn’t entirely new). 

- **“Harvest Now, Decrypt Later” Risk:** As mentioned earlier, one of the driving motivations to **act now** rather than later is the recognition of the harvest-now-decrypt-later threat. Adversaries (especially nation-states) are believed to be *already recording vast amounts of encrypted traffic*, with the expectation that they can decrypt it in the future when quantum computers are available. This especially concerns long-term sensitive data – for example, diplomatic communications, intelligence data, or personal data that might still be sensitive a decade or more from now. *“Even if an adversary can’t crack the encryption protecting our secrets at the moment, it could capture encrypted data and hold onto it, hoping a quantum computer will break it later – this idea is ‘harvest now, decrypt later.’”*<sup>4</sup>. The implication is that **some data is at risk retroactively**. If, say, around 2035 a quantum computer can decrypt your 2025 internet VPN traffic, anything intercepted in 2025 could be read. This has already led some sectors (like the US Government) to label certain types of encryption as “Quantum Risk” and to prioritize those links for early upgrade. For individuals and companies, it means that if you have data that needs to remain confidential for many years (think: health records, trade secrets, research data, etc.), you should consider transitioning to quantum-safe encryption sooner rather than later. Fortunately, communication protocols that achieve *perfect forward secrecy* (PFS), such as modern TLS, ensure that past sessions cannot be decrypted even if long-term keys are broken – *provided* the ephemeral session keys were protected with algorithms that are not weak to quantum attacks. (Many PFS key exchanges today use ECDH, which *is* vulnerable to quantum, thus the need to replace those with PQC key exchanges.)

- **Workforce and Ecosystem Readiness:** A softer challenge is the need for skilled personnel and robust implementations to carry out the migration. Quantum-safe cryptography is still a new field for many engineers. There’s a need for training and awareness so that developers implement PQC correctly. Additionally, the ecosystem of libraries, standards, and tools needs to mature. We need everything from optimized assembly implementations of lattice math to protocols for mixing PQ and classical creds, to certification processes (e.g., FIPS certification for PQC modules). Early adopters like Cloudflare contributing to OpenSSL and Google contributing to BoringSSL with PQC support are helping the ecosystem. Over time, we expect toolkits to embed PQC by default, easing the transition for application developers.

Despite these challenges, the momentum is clearly in favor of moving to quantum-resistant cryptography. The next few years (2025–2030) will likely see major strides in adoption. Organizations are beginning to inventory their cryptographic assets (a recommendation by NIST and ENISA is to first understand where and how you’re using crypto, and what would need changing) and run testbeds for PQC. International collaboration is also important; standards bodies in Europe, China, Russia, etc., are also working on or have their own post-quantum algorithm candidates. It will be a collective effort to ensure interoperability and global security.

## Conclusion and Future Outlook  
The advent of quantum computing represents a pivotal challenge for cryptography – often framed as a looming crisis but also an impetus for innovation. On one hand, quantum algorithms like Shor’s and Grover’s threaten to upend the security of the digital systems we rely on, rendering classical RSA/ECC-based protections obsolete and weakening symmetric encryption to a degree. On the other hand, we are witnessing a proactive and heartening response from the scientific and security communities: **the development of quantum-resistant cryptography is well underway and making tangible progress**. By 2024, we have viable post-quantum algorithms and even finalized standards, something that seemed aspirational just a decade ago. This new generation of cryptography – lattice-based, hash-based, code-based, etc. – promises to safeguard privacy and security in the quantum era, if deployed correctly. 

The interplay of quantum computing and cryptography is sometimes described as a cat-and-mouse game, but it’s better seen as a cycle of challenge and response. History in cryptography has shown that when a new attack capability emerges, defenders innovate and usually restore the balance (for example, increasing key lengths, or inventing entirely new schemes). Quantum computing is perhaps the greatest challenge cryptography has faced to date, but the current state of research suggests it’s a solvable challenge. The transition will not be instant nor easy – it will likely take a concerted effort over a decade or more to swap out vulnerable cryptosystems worldwide. There may be surprises along the way: new quantum algorithms could emerge, or unforeseen weaknesses in some post-quantum scheme might be discovered. Vigilance and continued research are essential. It’s also possible that quantum computing itself will face limits or delays, giving a bit more breathing room; however, betting on that would be unwise given the stakes.

In the meantime, organizations and individuals can start preparing by **staying informed** and **embracing crypto agility** – designing systems that can easily switch cryptographic algorithms. Many experts recommend a prudent approach: **begin deploying post-quantum solutions in a hybrid manner** (alongside classical crypto) in high-value systems, and develop a roadmap for broader migration as standards solidify,. The cost of being unprepared could be catastrophic, whereas being early has little downside. As one commentary put it, *whether the quantum breakthrough comes in 2030 or 2040, it will always feel too soon, so the only sane strategy is to act as if it’s imminent*.

In summary, the current state of quantum computing applications in cryptography is one of **intense progress and cautious optimism**. Quantum computers will undoubtedly transform many fields, and cryptography must transform with them. Thanks to global efforts, the tools to achieve quantum-resistant security are emerging just in time. The next few years will be critical in implementing these tools and thus ensuring that our digital world remains secure against the quantum-powered adversaries of the future. By combining academic insight, industry initiative, and perhaps a bit of quantum magic of our own, we can **decrypt the future** and keep it safe.

**Sources:**

1. Mamatha, G. S., et al. *“Post-Quantum Cryptography: Securing Digital Communication in the Quantum Era.”* arXiv preprint 2403.11741 (Mar 2024): Highlights the vulnerabilities of RSA/ECC to quantum algorithms and the emergence of PQC as a defense<sup>1</sup>.

2. Sibanda, Isla. *“The Rise of Quantum-Resistant Cryptography.”* IEEE Computer Society Tech News (Oct 3, 2024): Overview of quantum computing’s threat to RSA/ECC (via Shor’s algorithm) and the need for new cryptographic methods (lattice, hash-based, etc.), with discussion of NIST’s PQC project<sup>2</sup>.

3. NIST News. *“NIST Releases First 3 Finalized Post-Quantum Encryption Standards.”* (Aug 13, 2024): Announcement of finalized standards (Kyber-based KEM and two signature schemes) and urging immediate transition to PQC<sup>3</sup>.

4. NIST Cybersecurity Whitepaper. *“What Is Post-Quantum Cryptography?”* (2024): Q&A explaining quantum computing’s threat to current crypto, the need for PQC, timeline uncertainties (estimates from <10 years to decades), and “harvest now, decrypt later” risk<sup>4</sup>.

5. Ivezic, Marin. *“Grover’s Algorithm and Its Impact on Cybersecurity.”* PostQuantum Blog (updated May 2025): Explains Grover’s algorithm’s effect on symmetric encryption and hashing – effectively halving security – making the case for larger key sizes and PQC adoption.

6. QuSecure. *“AES-256 is Quantum-Resistant, RSA is Not.”* (2023): Notes that Grover’s algorithm cuts effective AES key length in half; recommends doubling keys (using AES-256) to counter quantum attacks<sup>5</sup>. Also cites research estimating ~6,600 error-corrected qubits would be needed to significantly threaten AES-256<sup>5</sup>.

7. Bas Westerbaan (Cloudflare). *“The State of the Post-Quantum Internet.”* Cloudflare Blog (Mar 5, 2024): Detailed status report on PQC adoption: mentions 2% of Cloudflare’s TLS connections are PQC-protected (with expected growth), Apple and Signal using PQC, expert survey on quantum timeline (50% chance by 2037), and NSA’s 2033 migration goal,. Also discusses symmetric crypto being “already” post-quantum secure and misconceptions about needing to double key sizes (arguing many symmetric schemes are fine as-is).

8. Jaques, Samuel, et al. *“On the practicality of quantum attacks on cryptography.”* (Referenced in Cloudflare blog): Analysis of qubit counts and noise levels needed to break RSA, suggesting tens of millions of noisy qubits (or a few thousand error-corrected) might suffice to break RSA-2048.

9. Gidney, Craig. *“How to factor 2048-bit RSA integers with less than a million noisy qubits.”* arXiv:2505.15917 (May 2025): Research paper reducing the estimated resources for quantum factoring of RSA-2048 from 20 million to <1 million qubits (with a longer runtime) through algorithmic improvements<sup>6</sup>.

10. Alvarado, Marel, et al. *“A Survey on Post-Quantum Cryptography: State-of-the-Art and Challenges.”* arXiv:2312.10430 (Dec 2023): Surveys PQC vs quantum cryptography, concluding that QKD’s practical limitations make PQC the preferred solution for now .

11. Computer Security Resource Center (NIST). *“On the practical cost of Grover’s algorithm for AES.”* (2021): NIST report analyzing how Grover’s algorithm affects symmetric ciphers, confirming that doubling key length (AES-256) is a sufficient countermeasure for the foreseeable future,<sup>5</sup>.

12. various sources via VentureBeat, CSO Online, etc., on recent claims and research: e.g., Chevignard et al. 2024 (hybrid classical-quantum factoring), Phys.org 2022 (on reduced qubit requirements), and the spurious 2023 claim of breaking RSA with a quantum annealer,. *(These underscore active research and occasional hype, reinforcing the need for measured, evidence-based assessment of quantum threats.)*

## Citations
1. [NIST Releases First 3 Finalized Post-Quantum Encryption Standards](https://www.nist.gov/news-events/news/2024/08/nist-releases-first-3-finalized-post-quantum-encryption-standards)
2. [What Is Post-Quantum Cryptography? | NIST](https://www.nist.gov/cybersecurity/what-post-quantum-cryptography)
3. [AES 256 is quantum-resistant | QuSecure](https://www.qusecure.com/aes-256-is-quantum-resistant-rsa-is-not/)
4. [[2505.15917] How to factor 2048 bit RSA integers with less than a ...](https://arxiv.org/abs/2505.15917)
5. [The state of the post-quantum Internet - The Cloudflare Blog](https://blog.cloudflare.com/pq-2024/)
6. [[2312.10430] A Survey on Post-Quantum Cryptography: State-of-the-Art ...](https://arxiv.org/abs/2312.10430)
